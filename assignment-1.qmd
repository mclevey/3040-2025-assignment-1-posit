---
title: "Neonatal Mortality Data Analysis"
subtitle: "SOCI 3040 -- Assignment 1"
author:
  - name: "A Student"
    email: student@mun.ca
    affiliations:
      - name: Sociology, Memorial University
  - name: "Another Student"
    email: student@mun.ca
    affiliations:
      - name: Criminology, Memorial University
format: html
abstract: "The deadline has been extended from Tuesday, January 28th to **Thursday, January 30th**. We will work on most of this assignment together in class, but you should plan to spend additional time refining your submission."
bibliography: refs.bib
---

# Assignment Overview

You may complete the assignment individually or in groups of 2-3. If working collaboratively, each member must submit their own assignment with the group’s names listed in the author metadata above.

Steps to Complete the Assignment:

1. Create a free or student account ($5/month) with PositCloud.
2. Create a new workspace.
3. In the workspace, create a new project from a Github repository using this link: https://github.com/mclevey/3040-posit.git.
4. Open `assignment-1.qmd` and update the author metadata at the top of the file.
5. Follow the instructions in the notebook, executing the code cells as you go. *Note that one of the instructions asks you to insert a citation to the assigned reading.* Citation information is already entered into the `refs.bib` file.
6. "Knit" your document to an HTML file. Make sure it executes without errors and preview the result.
7. Save the HTML file and upload it to the Dropbox on Brightspace.

# Imports

We’ll begin by loading the necessary R packages. Install any missing packages before proceeding.

```{r}
library("janitor")
library("knitr")
library("lubridate")
library("opendatatoronto")
library("tidyverse")
library("here")
```

# Neonatal Mortality

Neonatal mortality refers to a death that occurs within the first month of life. The neonatal mortality rate (NMR) is the number of neonatal deaths per 1,000 live births [@unigme]. The Third Sustainable Development Goal (SDG) calls for a reduction in NMR to 12. We'll will create a graph of the estimated NMR for the past 50 years for Argentina, Australia, Canada, and Kenya.

> **Objective**: Create a graph of estimated NMR over the past 50 years for Argentina, Australia, Canada, and Kenya.

## Workflow Step: Plan

Our dataset will need variables that specify the country and the year. It also needs to have a variable with the NMR estimate for that year for that country. Roughly, it should look like @fig-nmrexample-data. We want to make a graph with year on the x-axis and estimated NMR on the y-axis. Each country should have its own series. A quick sketch of what we are looking for is @fig-nmrexample-graph.^[These figures are from the assigned reading.]

::: {#fig-nmrexample layout-ncol="2"}
![Quick sketch of a potentially useful NMR dataset](figures/nmr_dataset_sketch.png){#fig-nmrexample-data width="85%"}

![Quick sketch of a graph of NMR by country over time](figures/NMRgraph.png){#fig-nmrexample-graph width="85%"}

Sketches of a dataset and graph about the neonatal mortality rate (NMR)
:::


### Workflow Step: Simulate 

To simulate some data that aligns with our plan, we will need three columns: `country`, `year`, and `NMR`. We can do this by repeating the name of each country 50 times with `rep()`, and enabling the passing of 50 years. Then we draw from the uniform distribution^[With a uniform probability distrubution, all options have an equal chance of being selected.] with `runif()` to simulate an estimated NMR value for that year for that country.

```{r}
set.seed(853)

simulated_nmr_data <-
    tibble(
        country =
            c(
                rep("Argentina", 50), rep("Australia", 50),
                rep("Canada", 50), rep("Kenya", 50)
            ),
        year =
            rep(c(1971:2020), 4),
        nmr =
            runif(n = 200, min = 0, max = 100)
    )

head(simulated_nmr_data)
```

> What, if anything, do you notice about this output? What is your understanding of the simulation process in general?

While this simulation works, it would be time consuming and error prone if we decided that instead of 50 years, we were interested in simulating, say, 60 years. One way to improve this code is to replace all instances of 50 with a `variable.` 

```{r}
number_of_years <- 50

simulated_nmr_data <-
    tibble(
        country =
            c(
                rep("Argentina", number_of_years), rep("Australia", number_of_years),
                rep("Canada", number_of_years), rep("Kenya", number_of_years)
            ),
        year =
            rep(c(1:number_of_years + 1970), 4),
        nmr =
            runif(n = number_of_years * 4, min = 0, max = 100)
    )

head(simulated_nmr_data)
```

The result will be the same, but now if we want to change from 50 to 60 years, we only have to make the change in one place.

> Using your knowledge of how **assignment** works in R, do your best to explain why using the variable `number_of_years` instead of the number 50 returns the same kind of results as before. However, note that the results are not exactly the same. Why do you think that is? And what happens if you change the value 50 to some other number?

As Rohan Alexander **(HI! INSERT A CITATION TO THE READING HERE!)** points out in the assigned reading, "we can have confidence in this simulated dataset because it is relatively straight forward, and we wrote the code for it. But when we turn to the real dataset, it is more difficult to be sure that it is what it claims to be. Even if we trust the data, we need to be able to share that confidence with others. One way forward is to establish some tests of whether our data are as they should be."

For instance, we expect:

- That "country" is exclusively one of these four: "Argentina", "Australia", "Canada", or "Kenya".
- That "year" is no smaller than 1971 and no larger than 2020, and is an integer, not a letter or a number with decimal places.
- That "nmr" is a value somewhere between 0 and 1,000, and is a number.

We can write a series of tests based on these features, that we expect the dataset to pass.


```{r}
simulated_nmr_data$country |>
    unique() == c("Argentina", "Australia", "Canada", "Kenya")

simulated_nmr_data$country |>
    unique() |>
    length() == 4

simulated_nmr_data$year |> min() == 1971
simulated_nmr_data$year |> max() == 2020
simulated_nmr_data$nmr |> min() >= 0
simulated_nmr_data$nmr |> max() <= 1000
simulated_nmr_data$nmr |> class() == "numeric"
```

> To the best of your current ability, explain what the tests above are doing. Try to provide an explanation of what each line of code is doing, and why it is important. Why is it important to validate datasets, even if they are simulated?

Now that we've developed these tests and applied to them to the simulated data, we can apply them tests to the real dataset!

### Workflow Step: Acquire

The UN Inter-agency Group for Child Mortality Estimation (IGME) [provides](https://childmortality.org/) NMR estimates that we can download and save. Note that this is a large file and may take some time to download. Actually, it's also too large to view in RStudio's `View()` function!

```{r}
igme_data_path <- here("data", "igme.csv")
igme_data_path
```

```{r}
raw_igme_data <-
    read_csv(
        file =
            "https://childmortality.org/wp-content/uploads/2021/09/UNIGME-2021.csv",
        show_col_types = FALSE
    )

write_csv(x = raw_igme_data, file = igme_data_path)
```
You'll see a warning print when you run this code. You can safely ignore it.

> Make sure you can download this data, save it to the `data/` subdirectory, and then read it back in. Do not proceed until you have done this!


```{r}
raw_igme_data <-
    read_csv(
        file = igme_data_path,
        show_col_types = FALSE
    )

raw_igme_data |>
    head(10)
```

> Take some time to browse the variables in the dataset. What do you notice? What do you think we need to do to clean this dataset? Note that you can find the codebook for this data at [https://childmortality.org/wp-content/uploads/2021/03/CME-Info_codebook_for_downloads.xlsx](https://childmortality.org/wp-content/uploads/2021/03/CME-Info_codebook_for_downloads.xlsx). 

You can also look up the names of the columns with `names()`:

```{r}
names(raw_igme_data)
```

Let's clean up the names and only keep the rows and columns we are interested in. Based on our plan, we are interested in rows where `Sex` is "Total", `Series Name` is "UN IGME estimate", `Geographic area` is one of "Argentina", "Australia", "Canada", and "Kenya", and the `Indicator` is "Neonatal mortality rate". 

After this we are interested in just a few columns: `geographic_area`, `time_period`, and `obs_value`.

```{r}
cleaned_igme_data <-
    clean_names(raw_igme_data) |>
    filter(
        sex == "Total",
        series_name == "UN IGME estimate",
        geographic_area %in% c("Argentina", "Australia", "Canada", "Kenya"),
        indicator == "Neonatal mortality rate"
    ) |>
    select(geographic_area, time_period, obs_value)

head(cleaned_igme_data)
```

We need to fix two other aspects: the class of `time_period` is character (string) when we need it to be a year, and the name of `obs_value` should be `nmr` to be more informative.

```{r}
cleaned_igme_data <-
    cleaned_igme_data |>
    mutate(
        time_period = str_remove(time_period, "-06"),
        time_period = as.integer(time_period)
    ) |>
    filter(time_period >= 1971) |>
    rename(nmr = obs_value, year = time_period, country = geographic_area)

head(cleaned_igme_data)
```

Finally, we can check that our dataset passes the tests that we developed based on the simulated dataset!

```{r}
cleaned_igme_data$country |>
    unique() == c("Argentina", "Australia", "Canada", "Kenya")

cleaned_igme_data$country |>
    unique() |>
    length() == 4

cleaned_igme_data$year |> min() == 1971
cleaned_igme_data$year |> max() == 2020
cleaned_igme_data$nmr |> min() >= 0
cleaned_igme_data$nmr |> max() <= 1000
cleaned_igme_data$nmr |> class() == "numeric"
```
> Did the cleaned dataset pass our tests? If not, what do you think we need to do to fix things?

```{r}
cleaned_igme_data_path <- here("data", "cleaned_igme_data.csv")
write_csv(x = cleaned_igme_data, file = cleaned_igme_data_path)
```

### Workflow Step: Explore/Understand

Now let's finally make a graph of estimated NMR using the cleaned dataset. First, we'll read the dataset back into memory.^[Yes, even though it's still in memory -- this is just practice!]

```{r}
cleaned_igme_data <-
    read_csv(
        here("data", "cleaned_igme_data.csv"),
        show_col_types = FALSE
    )

cleaned_igme_data |>
    head(10)
```

We can now make a graph of how NMR has changed over time and the differences between countries (@fig-nmrgraph).

```{r}
#| label: fig-nmrgraph
#| fig-cap: "Neonatal Mortality Rate (NMR), for Argentina, Australia, Canada, and Kenya (1971-2020)"

cleaned_igme_data |>
    ggplot(aes(x = year, y = nmr, color = country)) +
    geom_point() +
    theme_minimal() +
    labs(x = "Year", y = "Neonatal Mortality Rate (NMR)", color = "Country") +
    scale_color_brewer(palette = "Set1") +
    theme(legend.position = "bottom")

ggsave(
    filename = "figures/fig-nmrgraph.pdf",
    plot = last_plot(), 
    width = 8,          
    height = 6,         
    units = "in"        
)
```

### Workflow Step: Share 

::: {.callout-note appearance="minimal"}
Neonatal mortality refers to a death that occurs within the first month of life. In particular, the neonatal mortality rate (NMR) is the number of neonatal deaths per 1,000 live births. We obtain estimates for NMR for four countries---Argentina, Australia, Canada, and Kenya---over the past 50 years.

The UN Inter-agency Group for Child Mortality Estimation (IGME) provides estimates of the NMR at the website: https://childmortality.org/. We downloaded their estimates then cleaned and tidied the dataset using the statistical programming language R [@citeR].

We found considerable change in the estimated NMR over time and between the four countries of interest (@fig-nmrgraph). We found that the 1970s tended to be associated with reductions in the estimated NMR. Australia and Canada were estimated to have a low NMR at that point and remained there through 2020, with further slight reductions. The estimates for Argentina and Kenya continued to have substantial reductions through 2020.

Our results suggest considerable improvements in estimated NMR over time. NMR estimates are based on a statistical model and underlying data. The double burden\index{data!double burden} of data is that often high-quality data are less easily available for groups, in this case countries, with worse outcomes. Our conclusions are subject to the model that underpins the estimates and the quality of the underlying data, and we did not independently verify either of these.
:::

> Rewrite the above text in your own words. What do you think of the graph? What do you think of the data? What do you think of the conclusions? How far is Kenya from the UN's goal NMR rate? 

> More generally, what have you learned about the five-step data storytelling workflow in R/RStudio? How does it compare to what you learned with the examples of the Australian election outcomes and shelter usage rates in Toronto?

